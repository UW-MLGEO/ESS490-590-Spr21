{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fa3d2a9c-442b-44c2-bf4d-45bb544ec369",
    "_uuid": "bcba1675eebc008a35c21f6b64174161ff7d4c48"
   },
   "source": [
    "# Homework 7 (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4bef474-9b3a-4bfd-80ee-b79f7fa144dc",
    "_uuid": "73e8f01266e59393a11b6e00300eb916ee50662f"
   },
   "source": [
    "In this Homework, we will try to classify observations of space to be either stars, galaxies or quasars based on the RD14 from the Sloan Digital Sky Survey  (SDSS). The Sloan Digital Sky Survey is a project which offers public data of space observations. Observations have been made since 1998 and have been made accessible to everyone who is interested. \n",
    "\n",
    "http://www.sdss.org/\n",
    "![alt text](http://www.fingerprintdigitalmedia.com/wp-content/uploads/2014/08/sdss1.jpg)\n",
    "\n",
    "For this purpose a special 2.5 m diameter telescope was built at the Apache Point Observatory in New Mexico, USA. The telescope uses a camera of 30 CCD-Chips with 2048x2048 image points each. The chips are ordered in 5 rows with 6 chips in each row. Each row observes the space through different optical filters (u, g, r, i, z) at wavelengths of approximately 354, 476, 628, 769, 925 nm.\n",
    "\n",
    "\n",
    "In this homework we will train several classifier to predict the class of a celestial object based on the observations (features). We will practice data prep, dimensionality reduction, model design and training, model comparison, and feature importance selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9d4b609-9f0f-4296-8462-98975b2ece09",
    "_uuid": "16d228ddb3b0d71d6e13093552c04a21146b75e5"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13914766-c2fb-4801-8846-6c78e6d1cb03",
    "_uuid": "5bb212bdb34abc34f8bed1a0bc2d1a6287166221"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2b272b59-8c37-4e8e-a78a-ac5f50919d2e",
    "_uuid": "82c44461c45ae463a3d429f564f8bca17f8b0f4c"
   },
   "source": [
    "## 1) Data Preparation (20 points)\n",
    "\n",
    "We follow the following steps:\n",
    "* read (1 point)\n",
    "* clean (3 points)\n",
    "* correlate (4 points)\n",
    "* explore, spread of values (3 points)\n",
    "* dimensionality reduction (9 points)\n",
    "\n",
    "### 1.1 Data read\n",
    "Read the pandas fata frame from the csv file \"Skyserver_SQL2_27_2018.csv\" and skip the first row.\n",
    "\n",
    "**Task: read (1 point)**\n",
    "\n",
    "Save a copy of the data frame just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffb06ef6-73f7-4f42-ab42-5d5b5f773ba7",
    "_uuid": "04e88f8c9c12167a1c23e47b3e2046246510e983"
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of the data fields**\n",
    "\n",
    "* objid = Object Identifier, self explanatory.\n",
    "* ra = J2000 Right Ascension (r-band). Angular that is measured eastward along the celestial equator from the Sun at the March equinox to the hour circle of the point above the earth in question.   https://en.wikipedia.org/wiki/Right_ascension\n",
    "* dec = J2000 Declination (r-band). Angle that is measured north or south of the celestial equator, along the hour circle passing through the point in question. https://en.wikipedia.org/wiki/Declination\n",
    "\n",
    "\n",
    "\n",
    "The Gunn astronomic magnitude system. u, g, r, i, z represent the response of the 5 bands of the telescope.\n",
    "\n",
    "Further Information: http://astroweb.case.edu/ssm/ASTR620/mags.html \n",
    "* u = better of DeV/Exp magnitude fit\n",
    "* g = better of DeV/Exp magnitude fit\n",
    "* r = better of DeV/Exp magnitude fit\n",
    "* i = better of DeV/Exp magnitude fit\n",
    "* z = better of DeV/Exp magnitude fit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Run, rerun, camcol and field are features which describe a field within an image taken by the SDSS. A field is basically a part of the entire image corresponding to 2048 by 1489 pixels. \n",
    "* run = Run Number, which identifies the specific scan. \n",
    "* rereun = Rerun Number, which specifies how the image was processed.\n",
    "* camcol = Camera column, a number from 1 to 6, identifying the scanline within the run.\n",
    "* field = Field number, which typically starts at 11 (after an initial rampup time), and can be as large as 800 for particularly long runs.\n",
    "* specobjid = Object Identifier\n",
    "* class = object class (galaxy, star or quasar object): The class identifies an object to be either a galaxy, star or quasar. This will be the response variable which we will be trying to predict.\n",
    "\n",
    "* redshift = Final Redshift: In physics, **redshift** happens when light or other electromagnetic radiation from an object is increased in wavelength, or shifted to the red end of the spectrum. \n",
    "\n",
    "* plate = plate number: Each spectroscopic exposure employs a large, thin, circular metal **plate** that positions optical fibers via holes drilled at the locations of the images in the telescope focal plane. These fibers then feed into the spectrographs. Each plate has a unique serial number, which is called plate in views such as SpecObj in the CAS.\n",
    "\n",
    "* mjd = MJD of observation, **Modified Julian Date**, used to indicate the date that a given piece of SDSS data (image or spectrum) was taken.\n",
    "* fiberid = fiber ID. The SDSS spectrograph uses optical fibers to direct the light at the focal plane from individual objects to the slithead. Each object is assigned a corresponding **fiberID**. \n",
    "\n",
    "**Further information on SDSS images and their attributes:** \n",
    "\n",
    "http://www.sdss3.org/dr9/imaging/imaging_basics.php\n",
    "\n",
    "http://www.sdss3.org/dr8/glossary.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca3f2be5-d15c-47ef-bc29-9a254ce2199d",
    "_uuid": "776947da30d7e7e2b88bd87dca65eaa8b04b158c"
   },
   "source": [
    "### 1.2 Data Cleaning \n",
    "\n",
    "Basic stats about our dataset. \n",
    "\n",
    "**Task: Provide basic infor for the pandas dataframe head (0.5 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26b460b4-d472-440b-b690-d8c12f267944",
    "_uuid": "149d00bab55383b7014daf916df81410717b643a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "811c152a-331b-4b69-a7d3-ab52934ef15c",
    "_uuid": "7b054433b30b6ea6b1f9024ef323270d86874e76"
   },
   "source": [
    "**Task: Find the data types of the database (floats, string, etc etc) using the ``info()`` function (0.5 point).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd29718c-d53e-4b52-a9ee-b8a9a252d864",
    "_uuid": "926e1713524a5fcac0353e1d7c03d1f74042f348"
   },
   "outputs": [],
   "source": [
    "# information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f890c211-edfb-45d5-be7d-545eb358220b",
    "_uuid": "529e41f022c84c223fc508224b63b527677a61fc"
   },
   "source": [
    "Are there any obvious feature (or element of the dataframe) that should not impact our prediction?\n",
    " \n",
    "**objid** and **specobjid** are just identifiers for accessing the rows back when they were stored in the original databank. Therefore we will not need them for classification as they are not related to the outcome.\n",
    "The features **run**, **rerun**, **camcol** and **field** are values which describe parts of the camera at the moment when making the observation, e.g. 'run' represents the corresponding scan which captured the oject.\n",
    "\n",
    "Source: http://www.sdss3.org/dr9/imaging/imaging_basics.php\n",
    "\n",
    "**Task: Drop these columns in the pandas dataframe. (1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1246406-e5f7-4cb7-8365-50c8e44e19d9",
    "_uuid": "4d9519ab0d8b9f843219ce89531c3fc13dafc5be"
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75a847f1-0dfc-4228-9cbc-49d6034463e5",
    "_uuid": "9b01bc847e158cfa00d411ea687cb573a0037aef"
   },
   "source": [
    "Find our how many examples there are, how many attributes or feature, and the type of class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6723c745-8446-46f0-a866-8c22668607d3",
    "_uuid": "77495f8526975b41e2ba43063b82d807e8ba1109",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "47229348-1a06-4346-949b-1b2b135a20e9",
    "_uuid": "d03d6a82a73b4889fc9bfee64e0773acd9b09302"
   },
   "source": [
    "**Task: How many objects are in each class? (1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "980baf01-358b-4f40-b1cd-886a8463befe",
    "_uuid": "75724e4e2a11a567b6155503ce0671ae3f5e2e7d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the elements in each class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are \"GALAXY\", \"STAR\", and \"QSO\" (quasars). They are defined as strings, but we will convert them to integer in order to apply a loss function on the class labels during training. For this, we use the ``sklearn.preprocessing.LabelEncoder()`` function. We will do so and modify the classes in the dataframe. We should keep a copy of the original data frame to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_df_save = sdss_df # make a copy of the original data before cleaning it. That works well when the data is small.\n",
    "\n",
    "# encode class labels to integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(sdss_df['class'])\n",
    "sdss_df['class'] = y_encoded\n",
    "#  GALAXY = 0\n",
    "# STAR = 1\n",
    "# QSO = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data correlations\n",
    "Now let's find the most basic correlations among features. This can be done using the ``corr()`` function to apply on the pandas dataframe. Evaluate this function and comment on what feature is correlated among others. It is convenient to use the matplotlib function ``matshow()`` for clarity. ``seaborn`` is a python module that makes really pretty statistical plots https://seaborn.pydata.org/index.html#. Install it with ``pip`` and import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Plot the correlation matrix that can be called in the pandas dataframe. (2 points)**\n",
    "\n",
    "Hints:\n",
    "\n",
    "Use functions of ``heatmap``, add the labels in the axes. The colormap ``coolwarm`` is nice for divergent scales like correlations that vary between -1 and 1. The argument ``center=0`` ensures that the colormap is divergent from zero. Make sure to ignore the label column \"class\". Remember that dropping a column can be done in place ``sdss_df.drop('class', axis=1)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Reproduce the same plot for each of the three classes. (1 point)**\n",
    "You can select the values from the pandas dataframe by selecting over the column 'class'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same plot for Galaxies\n",
    "# \"GALAXY\" is label 0\n",
    "\n",
    "# Make the same plot for Stars (label 1)\n",
    "\n",
    "# make the same plots for quasars (label 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Can you comment on groups of observations that can be grouped together or that appear independent from each other given these correlations, and if there is any difference between the three celestial objects? (**1 point**)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6b86afe2-f926-416a-afd9-8b36edf9bbdd",
    "_uuid": "bc4bc3db7af9a1e46c21c5fda26e023137e0e239"
   },
   "source": [
    "### 1.5 Data exploration\n",
    "Given the structure of the correlations, we will explore the values of the data.\n",
    "\n",
    "#### 1.5.a. Distributions of redshift\n",
    "\"redshifting\" happens when the source of light is becoming more distant to the receiver: the object is moving away from Earth. \n",
    "\n",
    "**Task: plot histograms for the 'redshift' feature column for each class (1 point).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f7e55b21-caa1-4b91-8f5a-c465d56cc146",
    "_uuid": "5a6a061a52d8e4bb3286be05e8b31c0c656f3dfd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a44d0c69-fb05-4b09-99c3-d92dc1ec0b9a",
    "_uuid": "f389689f8d958bdd4e281089036af6d26c1c4d10"
   },
   "source": [
    "**Task : Describe briefly the difference between the three histograms. (0.5 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # answer -->\n",
    "* **Star:** The histogram looks like a truncated zero-centered normal distribution. It looks like stars are both coming toward and away from the Earth.\n",
    "\n",
    "* **Galaxy:** The redshift values may come from a slightly right-shifted normal distribution which is centered around 0.075. It looks like galaxies are moving away from the Earth but at slow speeds.\n",
    "\n",
    "* **QSO:** The redshift values for QSOs are a lot more uniformly distributed than for Stars or Galaxies. They are roughly evenly distributed from 0 to 3, than the occurences decrease drastically. For 4 oder ~5.5 there are some outliers. This probably means that quasards are moving away from the earth with a diverse range of speeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0cbe1c99-0148-4406-a11d-17d1efa44025",
    "_uuid": "7b2155d1a1261d2065a92008cb2a33d425f7b3dd"
   },
   "source": [
    "#### 1.5.b. Right ascension (ra) and declination (dec) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4dac296-e9a1-4a63-83fc-46c3ca2265a2",
    "_uuid": "4e248ae503d23d0dd3f2473108007ad7b899b47a"
   },
   "source": [
    "We will now plot the right ascension versus the declination depending on the class. You can use the ``lmplot`` function in ``seaborn`` (https://seaborn.pydata.org/generated/seaborn.lmplot.html) to represent the sky view of these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66068c6e-e97b-4e00-8baf-85d67ee6b155",
    "_uuid": "6e0aa853466d5c45afec6ac1efd4f9db2a013642"
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='ra', y='dec', data=sdss_df, hue='class', fit_reg=False, palette='coolwarm', size=6, aspect=2,legend=False)\n",
    "plt.legend(title='Class', loc='upper left', labels=['Galaxu', 'Star','Quasar'])\n",
    "plt.grid(True)\n",
    "plt.title('Equatorial coordinates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: do you see any obvious differences such that one could easily discriminate between the two coordinates? (0.5 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f3174f32-1e96-47d5-ab74-2a14f1e7b1f7",
    "_uuid": "32ac7f6965966d8f25013c5a2e1d2817d9e78cf3"
   },
   "source": [
    "#### 1.5.c Filters - u,g,r,i,z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27c33528-10f3-400f-a59a-b0c28416e00a",
    "_uuid": "4761d9058cb828d6e016fe43693019981ce22596"
   },
   "source": [
    "Recall: u, g, r, i, z represent the different wavelengths which are used to capture the observations. According to the correlation matrix, they are correlated for all three classes.\n",
    "\n",
    "Therefore it is interesting to see that band 'u' is less correlated to the other bands. \n",
    "\n",
    "**Task Plot histograms and discuss why you expect these features to be correlated (1 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of histograms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Anwer: -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa0a41b4-c96c-4193-8b86-fee485af4361",
    "_uuid": "4e3e3eccee7ba9f0f2bcb5b562bda8b4d3c5a424"
   },
   "source": [
    "### 1.6 Data Dimensionality Reduction\n",
    "At this point, we are left with 8 features: redshift, u, g, r, i, z, ra, and dec. Among these, the filters (u, g, r, i, z) are correlated to each other. There is therefore a potential for reducing the dimensions of the features using PCA on these 5 features.\n",
    "\n",
    "We will use the skilearn function ``sklearn.decomposition.PCA()`` to fit and transform the data into the PC coordinates. Lets' first explore how many PCs we need. Fit the PCA function over the total number of filters. You will fit the PCA function over an array with the columns selected from the dataframe. \n",
    "\n",
    "**Task: Perform the PCA over a max number of PCs, output the explained variance ratio values, decide on an appropriate maximum number of PC to use (6 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbb45762-272f-40b8-bde6-9d3dd9c1cd55",
    "_uuid": "8a97dca248a7b0473c784af669ea00b59017fa8a"
   },
   "outputs": [],
   "source": [
    "# anwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer on how many PCs to use*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now re-perform PCA with the number of PCs you found is most appropriate. Re-apply the fit-transform function. Update the dataframe by adding the PCA value(s) and dropping the columns of the 5 filter features.\n",
    "\n",
    "**Task: PCA again, fit and transform, update the dataframe with the new feature(s) (3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4e797850-cbb6-44f8-84d8-2649d9dcb461",
    "_uuid": "73423e72a3e388e8d6b8f16672a7b77215359cfe"
   },
   "source": [
    "## 2) Machine Learning Models (26 points)\n",
    "\n",
    "We will now train different models on this dataset. We have a total of 8 features, 3 classes, and 10,000 samples. We will use K-Nearest Neighbors, Naive Bayes, Random Forest, Support Vector Machine, Multi Layer Perceptron.\n",
    "\n",
    "We now follow a normal machine learning workflow:\n",
    "* Feature scaling (2 points)\n",
    "* Train/test set split (2 points)\n",
    "* Model design, training, testing (15 points)\n",
    "* Model comparisons, pick your winner, discuss feature importance using Random Forest. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0a8fc626-e05b-483e-bed1-17c5be108903",
    "_uuid": "282a92a1d893a96b40b70b1c6d1fae063ba08ba3"
   },
   "source": [
    "### 2.1 Feature Scaling\n",
    "Scaling all values to be within the (0, 1) interval will reduce the distortion due to exceptionally high values and make some algorithms converge faster. You can scale the features only by dropping the \"class\" column without modifying the dataframe in place, using the pandas function ``drop()``.\n",
    "\n",
    "**Task: Scale just the features (2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "23fc8398-331d-4164-8779-0516264ece29",
    "_uuid": "c147b9e899cc2dd508d736274c856f88fb49321d"
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "13e1fd6f-820c-4098-a486-0079b300e6c9",
    "_uuid": "e76e964a4b93c27e1ab01c24a06be09d8b304970"
   },
   "source": [
    "### 2.2 Test, train, validation data sets.\n",
    "**Task: Split the data into a training and a test part.  (2 points)**\n",
    "\n",
    "The models will be trained on the training data set and tested on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a94f2305-4f2a-4d11-b368-528820d28b0b",
    "_uuid": "da9a96996b695f8ca2c268f43106e179ba6be1f5"
   },
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation time is important to account for when scaling up the data set and the model size. You can evaluate the relative computational time using the function ``time.perf_counter()`` to evaluate the absolute time. Then compare the computational time by making the difference between two time stamps:\n",
    "\n",
    "``t1=time.perf_counter()``\n",
    "\n",
    "``t2=time.perf_counter()``\n",
    "\n",
    "``tcomp = t2 - t1``\n",
    "\n",
    "We will also assess the model performance of these multi-class classifiers. We will evaluate the average of the scores over the 3 class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "label_name = ['Star','Galaxy','Quasar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will be testing over several classifiers. Follow the steps:\n",
    "1. model definition/design\n",
    "2. training\n",
    "3. prediction on test\n",
    "4. evaluation: a) print the classification_report; b) save the precision, recall, fscore and accuracy in variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d74dbe6b-ebf8-4b61-b568-c2dabc031e5c",
    "_uuid": "3d19792d9ae5a949d2c524fb0c701a4084051816"
   },
   "source": [
    "### 2.3.a K Nearest Neighbors (3 points)\n",
    "Check out the function arguments and definition here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a16b9525-b3c9-46cf-8714-12707caf2502",
    "_uuid": "817a9fd86ca3d5195046fed7a72750538dee3051"
   },
   "outputs": [],
   "source": [
    "#answer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "print(\"Classifying using K-nearest Neighbors\")\n",
    "\n",
    "# model design\n",
    "\n",
    "# training\n",
    "\n",
    "# evaluation on test\n",
    "\n",
    "# print the classification report\n",
    "# save values of precision, recall, fscore, accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd50994d-fa25-4866-8a61-9d316a763a4a",
    "_uuid": "e901dbdaed422f26f42d9396a3b7a668c876f401"
   },
   "source": [
    "### 2.3.b Naive Bayes (3 points)\n",
    "Check out the sklearn tutorial pages here: https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes. We propose to use the Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23f16ebfd52f887cb78922a22ddfac00f3228bca"
   },
   "source": [
    "Naive Bayes assumes the data to be normally distributed which can be achieved by scaling using the MaxAbsScaler. For this example then we will use the unscaled data, then rescale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2db753f8-9832-4b47-9ba8-35db1448602f",
    "_uuid": "39aa691fa46edc353cf096543a19fa9d9bc1498f"
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "print(\"Classifying using Gaussian Naive Bayes\")\n",
    "\n",
    "# model design\n",
    "\n",
    "# re-scale the data\n",
    "sdss = scaler_gnb.fit_transform(sdss_df.drop('class', axis=1))\n",
    "X_train_gnb, X_test_gnb, y_train_gnb, y_test_gnb = train_test_split(sdss, sdss_df['class'], test_size=0.33)\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "# evaluation\n",
    "\n",
    "# evaluation: \n",
    "# print the classification report\n",
    "\n",
    "# save values of precision, recall, fscore, accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75b6b173-0875-4716-b458-7b741295fcf2",
    "_uuid": "d28d0e8f0d89945c4cb989b19d1829a50987ccdc"
   },
   "source": [
    "### 2.3.c Random Forest Classifier (2 points)\n",
    "Check out the tutorial page here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5d4a318-08c2-4172-8755-a82aa4e0cafc",
    "_uuid": "9dc11189c6289f7b3f0bb982bdf0c6b82da3e8d3"
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"Classifying using Random Forest Classifiers\")\n",
    "\n",
    "\n",
    "# model design\n",
    "\n",
    "# training\n",
    "\n",
    "# evaluation\n",
    "\n",
    "\n",
    "# evaluation: \n",
    "# print the classification report\n",
    "\n",
    "# save values of precision, recall, fscore, accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15b03625-4960-45a9-9751-b8e3ea82cfed",
    "_uuid": "ce81bb5c1480e8cf041153ffd04efa02fbf1c6ef"
   },
   "source": [
    "### 2.3.d Support Vector Machine Classifier (2 points)\n",
    "Check out the sklearn information page here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c50ce8dd-8a29-4cd5-80aa-68e13f2f6cea",
    "_uuid": "546fec58bfc86bd223f59efeac49abc5041a91c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "from sklearn.svm import SVC\n",
    "print(\"Classifying using Support Vector Machine Classfiers\")\n",
    "\n",
    "# model design\n",
    "\n",
    "# training\n",
    "\n",
    "# evaluation\n",
    "\n",
    "# evaluation: \n",
    "# print the classification report\n",
    "\n",
    "# save values of precision, recall, fscore, accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.e Multi-Layer Perceptron (3 points)\n",
    "\n",
    "Check out the information page here: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "print(\"Classifying using Multi Layer Perceptron Classifier\")\n",
    "\n",
    "\n",
    "# model design\n",
    "\n",
    "# training\n",
    "\n",
    "# evaluation\n",
    "\n",
    "# evaluation: \n",
    "# print the classification report\n",
    "\n",
    "# save values of precision, recall, fscore, accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model performance and comparison \n",
    "\n",
    "### 2.4.a Confusion Matrix and interpretation\n",
    "\n",
    "**Task: Plot the confusion matrix (2 points)**\n",
    "\n",
    "Use the sklearn function ``plot_confusion_matrix``. Find help here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html. We tested 5 models, make suplots, set the title on each subplots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Comment on what you see the best classifier is likely to be (1 point).** You can also comment on the misclassification and confusion rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1018b7a-65f5-46d3-9076-544fea2ea1ee",
    "_uuid": "207493115d3d29e59fce048de6e25e82e7adc9fd"
   },
   "source": [
    "### 2.4.a K Fold Cross Validation\n",
    "We will now perform k fold cross valdiation for the classifiers. We use the function ``cross_val_score`` on each ewstimator, on the training set, with 10 folds, and use accuracy as a score metric.\n",
    "\n",
    "**Task: perform the cross validation over K folds, output the mean and standard deviation of the accuracy (3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c330298-5c44-4c4f-81c6-633082a644d0",
    "_uuid": "277ceb9eea218726a798af0f9d1dfce6d56fbb0b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# print(\"K-nearest neighbors Mean:\", scores_knn.mean(),\"Standard Deviation:\", scores_knn.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "80b3da72-6711-42fb-93e3-6670112cd96c",
    "_uuid": "0941b7073b9d12b655476b6e44d453c065004478"
   },
   "source": [
    "**Task: Which method won the Xval test (1 point) ?**\n",
    "\n",
    "see the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- answer here -->\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1d7e36a9-414c-4212-a86c-763ca8422b86",
    "_uuid": "937ada3280f7e4de9b7cb022c47c0af1908238e6"
   },
   "source": [
    "### 2.4.c And the winner is ...\n",
    "\n",
    "Let's compare the results. \n",
    "**Task: Create a pandas dataframe with all of the performance metrics, including the results from K-fold cross validation. (2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a79815ff-1d64-48ec-996d-32bcbba98250",
    "_uuid": "c1fcf42a95967c7d25394c755e5014b027681d23"
   },
   "outputs": [],
   "source": [
    "# create data frame\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Naive Bayes', 'Random Forest', 'SVC','ANN'],\n",
    "    'Accuracy': [,,,,,],\n",
    "    'Precision': [, , , ,],\n",
    "    'Recall': [, ,, ,],\n",
    "    'Fscore': [, ,, ,],\n",
    "    'Kfold_accuracy_mean': [,,,,,],\n",
    "    'Kfold_accuracy_std': [,,,,,]})\n",
    "# sort values by the Fscore with the greatest value first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07452e0e-4f68-4f7c-a368-97ed43251eb4",
    "_uuid": "d108af400cc3ddb2bae13b870688d7149300c0f6"
   },
   "source": [
    "**Task: Comment on the accuracy and performance and choose a winner. (1 point)**\n",
    "\n",
    "see the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- answer here -->\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d6084f2-7121-4ef6-8f62-ce434f94f4ea",
    "_uuid": "91e2f9ced455f5a8f02a80cb5ff035ba3228f7f4"
   },
   "source": [
    "## 3 Summary (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d501e81-e7bf-4212-89b0-7e4dda3afd45",
    "_uuid": "8538142325bbaf4c09449126856a8cf0725aeabe"
   },
   "source": [
    "### 3.1 Feature Importance using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58abedc0-f5ba-497e-8037-4fd6e03e283a",
    "_uuid": "d201ab385d30b19c444b79d0d0b7697f9161f888"
   },
   "source": [
    "Decision Trees have the unique property of being able to order features by their ability to split between the classes. If some features dominate over other in the predictive power of classes, one can further reduce the dimension of the features for additional analysis. The vector of feature importance is the module ``rfc.feature_importances_``, sorted with ascending importance. Store the vector of importance .\n",
    "\n",
    "**Task: plot a bar plot using the function ``matplotlib.pyplot.bar``. (2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1684a815-20b7-47cd-ba41-d326249961e2",
    "_uuid": "12d49c95b6b762d0cf43eba7c28818237fa3ae97",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "# vector of importance\n",
    "# vector of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c20a7dc7-7226-4970-b480-44150db5ae8e",
    "_uuid": "27931b2ee5325ff26b194ce646604116f315996b"
   },
   "source": [
    "**Task: What are the top three features (1 point)?**\n",
    "\n",
    "enter in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- answer -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93e6bbb6-c774-4ab9-b2a8-f71ee48196ed",
    "_uuid": "d1f96b80f16c196f063143c7afc88254474dd4ea"
   },
   "source": [
    "In this notebook, you have learned that redshift was the best predictor of what object you are observing. Now, did you actualy need to do this all to find this out? Probably not if you were an astrophysicist! But hey, we are not. So great job!\n",
    "\n",
    "**Task: Briefly comment on what you have learned (1 point)**\n",
    "\n",
    "see the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- answer -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
